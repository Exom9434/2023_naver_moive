{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404a2ba6",
   "metadata": {},
   "source": [
    "\"\"\"5가지 요구사항 : \n",
    "\n",
    "1. 웹크롤링을 통하여 관심주제에 대한 감정분석 데이터를 수집하고 수집한 내용과 코드 설명을 병행하여 제시하세요\n",
    "\n",
    "   *참조 : 7주차 실습 코드 3. 종합실습 코드를 참조하여 새롭게 크롤링\n",
    "\n",
    "2. Konlpy 또는 정규표현식(re) 라이브러리를 이용하여 위에서 수집한 감정분석에 대한 택스트 데이터에 대하여 전처리를 하고 적용한 절차와 코드를 설명하세요. \n",
    "\n",
    "3. 2항의 전처리 결과를 문서별 코퍼스를 토큰화하여 DTM, TF-IDF에 의한 대략적인 키워드에 대한 빈도를 분석하고 결과를 설명하세요. \n",
    "\n",
    "4. 위에서 처리된 내용을 기초로 로지스틱 회귀분석에 의한 감정분석을 실시하고 계수들의 웨이트를 이용한 긍정과 부정의 키워드를 시각화하여 보여주고 코드와 결과를 설명하세요.\n",
    "\n",
    "5. 위에서 분석한 결과를 기초로 빈도수와 긍정 부정 키워드의 관계, 자료의 불균형과 모형의 예측 정확도의 관계에 대하여 위에서 분석한 사례를 들어 논하세요.   \n",
    "\n",
    "\"\"\"\n",
    "문제의식: 영화 평가에 있어 시대에 따른 표현법의 차이에 대한 의문\n",
    "절차 1: 2014 ~ 2023 각 연도별 흥행 상위 10위 영화 목록을 구한다.\n",
    "절차 2: 2019 ~ 2023 개봉영화와 2014 ~ 2018 개봉영화의 별점과 평가를 수집한다.\n",
    "절차 3: 각각의 코퍼스를 train set과 test set으로 구분한다.\n",
    "절차 4: 2019 ~ 2023 개봉영화 train set으로 훈련한 모델을 두 개의 test set에 적용하여 정확도를 비교한다\n",
    "절차 5: 2014 ~ 2013 개봉영화 train set으로 훈련한 모델을 두 개의 test set에 적용하여 정확도를 비교한다\n",
    "예측 결과1: 시의 적절한 훈련 데이터 수집의 필요성에 대해 할 수 있다.\n",
    "예측 결과2: 시대에 따른 영화 평가 방식의 표현법 차이를 수치화 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c1bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import Request, urlopen\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e40d46",
   "metadata": {},
   "source": [
    "# 1. 데이터 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기간 내 전체 영화 대상으로는 크롤링 시간이 장시간 소모되어 대상변경\n",
    "#영진위 api로부터 각 년도간 영화정보 저장\n",
    "# start_year = 2014\n",
    "# end_year = 2023\n",
    "# api_key = '1b7d7d5da614bb2d2974f2a6ca95cded'\n",
    "# raw_df = pd.DataFrame(index=range(0,1), columns = ['moiveListResult','moiveList'])\n",
    "\n",
    "# for page_num in range(1,1469):\n",
    "#     api_url = f'http://kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieList.json?key={api_key}&openStartDt={start_year}&openEndDt={end_year}&curPage={page_num}'\n",
    "#     request = Request(api_url)\n",
    "#     response = urlopen(request).read()\n",
    "#     response_json = json.loads(response)\n",
    "#     response_df = pd.DataFrame(response_json['movieListResult']['movieList'])\n",
    "#     raw_df = pd.concat([raw_df, response_df], axis=0)\n",
    "#     print(str(page_num) + '페이지 조회했습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567dcc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수동으로 구한 연도별 흥행성적 top 10 영화 정보 Import\n",
    "movie_ranking_df = pd.read_csv('movie_ranking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ranking_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ada4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ranking_df['개봉일'] = movie_ranking_df['개봉일'].str[:4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smaller_than_2019 = movie_ranking_df[movie_ranking_df['개봉일'] < 2019]\n",
    "df_greater_or_equal_to_2019 = movie_ranking_df[movie_ranking_df['개봉일'] >= 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_movie_names = df_smaller_than_2019['영화명'].tolist()\n",
    "newer_movie_names = df_greater_or_equal_to_2019['영화명'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ced5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(older_movie_names[:5])\n",
    "print(newer_movie_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "times = 0\n",
    "for movie_name in older_movie_names:\n",
    "    # 드라이버 사용해서 크롬 열기\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(f'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=영화+{movie_name}+평점')\n",
    "    time.sleep(15)\n",
    "    driver.execute_script(\"window.scrollTo(0, 800)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 스크롤용 경로 생성\n",
    "    x_path = \"/html/body/div[3]/div[2]/div/div[1]/div[2]/div[2]/div[2]/div/div[2]/div[6]\"\n",
    "    try:\n",
    "        to_scroll = driver.find_element_by_xpath(x_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)} for {movie_name}\")\n",
    "        continue\n",
    "        \n",
    "    # 별점과 코멘트 초기화\n",
    "    counts = 0\n",
    "    movie_comments = []\n",
    "    movie_ratings = []\n",
    "\n",
    "    while True:\n",
    "\n",
    "        all_contents = driver.find_elements(By.CSS_SELECTOR, \"div.lego_review_list._scroller\")\n",
    "\n",
    "        flag = False  # Flag variable to track if break has already been executed\n",
    "\n",
    "        for content in all_contents:\n",
    "            li_comments = content.find_elements(By.CSS_SELECTOR, \"span.desc._text\")\n",
    "            li_ratings = content.find_elements(By.CSS_SELECTOR, \"div.area_text_box\")\n",
    "            for li_comment in li_comments[counts:]:\n",
    "                movie_comments.append(li_comment.text)\n",
    "\n",
    "            for li_rating in li_ratings[counts:]:\n",
    "                rating_value = li_rating.get_attribute(\"textContent\").replace(\"별점(10점 만점 중)\", \"\").strip()\n",
    "                movie_ratings.append(int(rating_value))\n",
    "\n",
    "        if len(movie_comments) == counts:\n",
    "            flag = True  # Set flag to True if the break statement is executed\n",
    "            break\n",
    "\n",
    "        if flag:\n",
    "            print('종료')\n",
    "            break\n",
    "        counts = len(movie_comments)\n",
    "        times += 1\n",
    "        print(str(movie_name) +' ' + str(times) + ' 회 실행했습니다')\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", to_scroll)\n",
    "        time.sleep(3)\n",
    "\n",
    "        \n",
    "    if len(movie_comments) == 0:\n",
    "        continue\n",
    "    driver.quit()\n",
    "    # 영화정보로 딕셔너리 생성\n",
    "    movie_data = {\n",
    "        'movieName': [movie_name] * len(movie_comments),\n",
    "        'comments': movie_comments,\n",
    "        'ratings': movie_ratings\n",
    "    }\n",
    "\n",
    "    # data 리스트에 정보추가\n",
    "    data.extend(pd.DataFrame(movie_data).to_dict('records'))\n",
    "\n",
    "older_movie_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "times = 0\n",
    "for movie_name in newer_movie_names:\n",
    "    # 드라이버 사용해서 크롬 열기\n",
    "    driver = webdriver.Chrome('chromedriver_mac_arm64/chromedriver')\n",
    "    driver.get(f'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=영화+{movie_name}+평점')\n",
    "    time.sleep(15)\n",
    "    driver.execute_script(\"window.scrollTo(0, 800)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 스크롤용 경로 생성\n",
    "    x_path = \"/html/body/div[3]/div[2]/div/div[1]/div[2]/div[2]/div[2]/div/div[2]/div[6]\"\n",
    "    try:\n",
    "        to_scroll = driver.find_element_by_xpath(x_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)} for {movie_name}\")\n",
    "        continue\n",
    "        \n",
    "    # 별점과 코멘트 초기화\n",
    "    counts = 0\n",
    "    movie_comments = []\n",
    "    movie_ratings = []\n",
    "\n",
    "    while True:\n",
    "\n",
    "        all_contents = driver.find_elements(By.CSS_SELECTOR, \"div.lego_review_list._scroller\")\n",
    "\n",
    "        flag = False  # Flag variable to track if break has already been executed\n",
    "\n",
    "        for content in all_contents:\n",
    "            li_comments = content.find_elements(By.CSS_SELECTOR, \"span.desc._text\")\n",
    "            li_ratings = content.find_elements(By.CSS_SELECTOR, \"div.area_text_box\")\n",
    "            for li_comment in li_comments[counts:]:\n",
    "                movie_comments.append(li_comment.text)\n",
    "\n",
    "            for li_rating in li_ratings[counts:]:\n",
    "                rating_value = li_rating.get_attribute(\"textContent\").replace(\"별점(10점 만점 중)\", \"\").strip()\n",
    "                movie_ratings.append(int(rating_value))\n",
    "\n",
    "        if len(movie_comments) == counts:\n",
    "            flag = True  # Set flag to True if the break statement is executed\n",
    "            break\n",
    "\n",
    "        if flag:\n",
    "            print('종료')\n",
    "            break\n",
    "        counts = len(movie_comments)\n",
    "        times += 1\n",
    "        print(str(movie_name) + ' ' + str(times) + ' 회 실행했습니다')\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", to_scroll)\n",
    "        time.sleep(3)\n",
    "\n",
    "        \n",
    "    if len(movie_comments) == 0:\n",
    "        continue\n",
    "    driver.quit()\n",
    "    # 영화정보로 딕셔너리 생성\n",
    "    movie_data = {\n",
    "        'movieName': [movie_name] * len(movie_comments),\n",
    "        'comments': movie_comments,\n",
    "        'ratings': movie_ratings\n",
    "    }\n",
    "\n",
    "    # data 리스트에 정보추가\n",
    "    data.extend(pd.DataFrame(movie_data).to_dict('records'))\n",
    "\n",
    "\n",
    "newer_movie_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c08fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv 파일로 데이터 백업\n",
    "newer_movie_df.to_csv('newer_movie_df.csv')\n",
    "older_movie_df.to_csv('older_movie_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규표현식으로 데이터 1차 처리\n",
    "import re\n",
    "older_movie_df['comments'] = older_movie_df['comments'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "newer_movie_df['comments'] = newer_movie_df['comments'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd316a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#별점에 따른 긍정/부정 분리\n",
    "older_movie_df['PN'] = older_movie_df['ratings'].apply(lambda rating: 1 if rating >= 6 else 0)\n",
    "newer_movie_df['PN'] = newer_movie_df['ratings'].apply(lambda rating: 1 if rating >= 6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992249ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stopwords 구성\n",
    "#불용어 사전 출처 https://www.ranks.nl/stopwords/korean\n",
    "stop_words = []\n",
    "with open(stop_words_txt) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "stop_words = [line.rstrip('\\n') for line in lines]\n",
    "print(stop_words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96875bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_tokens ,older_corpus = [],[]\n",
    "for comment in older_movie_df['comments']:\n",
    "    temp_X = mecab.morphs(comment) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stop_words] # 불용어 제거\n",
    "    older_tokens.append(temp_X)\n",
    "    older_corpus.append(' '.join(temp_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee484f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_tokens ,newer_corpus = [],[]\n",
    "for comment in newer_movie_df['comments']:\n",
    "    temp_X = mecab.morphs(comment) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stop_words] # 불용어 제거\n",
    "    newer_tokens.append(temp_X)\n",
    "    newer_corpus.append(' '.join(temp_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#오래된 영화 긍정/부정 토큰 저장\n",
    "p_older_tokens, n_older_tokens = [], []\n",
    "\n",
    "for i, token in enumerate(older_tokens):\n",
    "    if older_movie_df['PN'].values[i] == 1:  \n",
    "        p_older_tokens.append(token)\n",
    "    else :\n",
    "        n_older_tokens.append(token)\n",
    "\n",
    "print(n_older_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1045f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#최신 영화 긍정/부정 토큰 저장\n",
    "p_newer_tokens, n_newer_tokens = [], []\n",
    "\n",
    "for i, token in enumerate(newer_tokens):\n",
    "    if newer_movie_df['PN'].values[i] == 1: \n",
    "        p_newer_tokens.append(token)\n",
    "    else :\n",
    "        n_newer_tokens.append(token)\n",
    "\n",
    "print(n_newer_tokens)\n",
    "print(p_newer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_older_corpus, p_older_corpus = [],[]\n",
    "for tokens in p_older_tokens:\n",
    "    for token in tokens:\n",
    "        p_older_corpus.append(''.join(token))\n",
    "for tokens in n_older_tokens:\n",
    "    for token in tokens:\n",
    "        n_older_corpus.append(''.join(token))\n",
    "p1_older_corpus = ' '.join(p_older_corpus).split()\n",
    "n1_older_corpus = ' '.join(n_older_corpus).split()\n",
    "print(n1_older_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_newer_corpus, p_newer_corpus = [],[]\n",
    "for tokens in p_newer_tokens:\n",
    "    for token in tokens:\n",
    "        p_newer_corpus.append(''.join(token))\n",
    "for tokens in n_newer_tokens:\n",
    "    for token in tokens:\n",
    "        n_newer_corpus.append(''.join(token))\n",
    "p1_newer_corpus = ' '.join(p_newer_corpus).split()\n",
    "n1_newer_corpus = ' '.join(n_newer_corpus).split()\n",
    "print(n1_newer_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c79ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(p1_older_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e28e59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "older_counter_p = Counter(p1_older_corpus)\n",
    "older_counter_n = Counter(n1_older_corpus)\n",
    "newer_counter_p = Counter(p1_newer_corpus)\n",
    "newer_counter_n = Counter(n1_newer_corpus)\n",
    "print(older_counter_p.most_common(10))\n",
    "print(older_counter_n.most_common(10))\n",
    "print(newer_counter_p.most_common(10))\n",
    "print(newer_counter_n.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30315604",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 설치된 폰트 출력\n",
    "font_list = [font.name for font in fm.fontManager.ttflist]\n",
    "font_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "pos = nltk.Text(p1_older_corpus)\n",
    "neg = nltk.Text(n1_older_corpus)\n",
    "plt.rcParams['font.family'] = 'AppleMyungjo'\n",
    "\n",
    "plt.figure(1)\n",
    "pos.plot(30)\n",
    "\n",
    "plt.figure(2)\n",
    "neg.plot(30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661de305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos = nltk.Text(p1_newer_corpus)\n",
    "neg = nltk.Text(n1_newer_corpus)\n",
    "plt.rcParams['font.family'] = 'AppleMyungjo'\n",
    "\n",
    "plt.figure(1)\n",
    "pos.plot(30)\n",
    "\n",
    "plt.figure(2)\n",
    "neg.plot(30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc58bde",
   "metadata": {},
   "source": [
    "# 전체 텍스트 대상 tf-idf 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dictionary = gensim.corpora.Dictionary(older_tokens)\n",
    "g_corpus = [g_dictionary.doc2bow(text) for text in older_tokens]\n",
    "vector = CountVectorizer(vocabulary=g_dictionary.token2id)\n",
    "older_dtm = vector.fit_transform(older_corpus).toarray()\n",
    "col = g_dictionary.token2id.keys()\n",
    "pd.DataFrame(older_dtm, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfTransformer()\n",
    "older_tf_idf = tfidf_vectorizer.fit_transform(older_dtm).toarray()\n",
    "col = g_dictionary.token2id.keys()\n",
    "print(older_tf_idf.shape)\n",
    "pd.DataFrame(older_tf_idf, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(older_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868face1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_older_tf_idf = pd.DataFrame(older_tf_idf, columns=col)\n",
    "pd_older_tf_idf.sum().sort_values(ascending=False)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef05871",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dictionary = gensim.corpora.Dictionary(newer_tokens)\n",
    "g_corpus = [g_dictionary.doc2bow(text) for text in newer_tokens]\n",
    "vector = CountVectorizer(vocabulary=g_dictionary.token2id)\n",
    "newer_dtm = vector.fit_transform(newer_corpus).toarray()\n",
    "col = g_dictionary.token2id.keys()\n",
    "pd.DataFrame(newer_dtm, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfTransformer()\n",
    "newer_tf_idf = tfidf_vectorizer.fit_transform(newer_dtm).toarray()\n",
    "col = g_dictionary.token2id.keys()\n",
    "print(newer_tf_idf.shape)\n",
    "pd.DataFrame(newer_tf_idf, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5225ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_newer_tf_idf = pd.DataFrame(newer_tf_idf, columns=col)\n",
    "pd_newer_tf_idf.sum().sort_values(ascending=False)[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51c4ef",
   "metadata": {},
   "source": [
    "# 3.로지스틱 회귀에 의한 감정분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd518302",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_movie_df['PN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_movie_df['PN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = older_tf_idf\n",
    "y = older_movie_df['PN']\n",
    "older_data = pd.concat([y,pd.DataFrame(X)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a800e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newer_tf_idf\n",
    "y = newer_movie_df['PN']\n",
    "newer_data = pd.concat([y,pd.DataFrame(X)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_train_df,older_test_df = train_test_split(older_data, test_size = 0.2, random_state=256)\n",
    "newer_train_df,newer_test_df = train_test_split(newer_data, test_size = 0.2, random_state=256)\n",
    "older_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_x_train = older_train_df.drop(['PN'], axis=1)\n",
    "older_y_train = older_train_df['PN']\n",
    "older_x_test = older_test_df.drop(['PN'], axis=1)\n",
    "older_y_test = older_test_df['PN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e382462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit in training set\n",
    "older_lr = LogisticRegression(random_state = 0)\n",
    "older_lr.fit(older_x_train,older_y_train)\n",
    "\n",
    "# predict in test set\n",
    "older_y_pred = older_lr.predict(older_x_test)\n",
    "\n",
    "older_a1 = accuracy_score(older_y_test, older_y_pred)\n",
    "older_p1 = precision_score(older_y_test, older_y_pred)\n",
    "older_r1 =recall_score(older_y_test, older_y_pred)\n",
    "older_f1= f1_score(older_y_test, older_y_pred)\n",
    "print('accuracy: %.2f' % older_a1 )\n",
    "print('precision: %.2f' % older_p1)\n",
    "print('recall: %.2f' % older_r1)\n",
    "print('F1: %.2f' % older_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "confu = confusion_matrix(y_true = older_y_test, y_pred = older_y_pred)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(confu, annot=True, annot_kws={'size':15}, cmap='OrRd', fmt='.10g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_positive_random_idx = older_movie_df[older_movie_df['PN']==1].sample(1000, random_state=12).index.tolist()\n",
    "older_negative_random_idx = older_movie_df[older_movie_df['PN']==0].sample(1000, random_state=12).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ae37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_random_idx = older_positive_random_idx + older_negative_random_idx\n",
    "x = older_tf_idf[older_random_idx]\n",
    "y = older_movie_df['PN'][older_random_idx]\n",
    "older_x_train2, older_x_test2, older_y_train2, older_y_test2 = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_lr2 = LogisticRegression(random_state = 0)\n",
    "older_lr2.fit(older_x_train2, older_y_train2)\n",
    "older_y_pred2 = older_lr2.predict(older_x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d8369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict in test set\n",
    "older_a2 = accuracy_score(older_y_test2, older_y_pred2)\n",
    "older_p2 = precision_score(older_y_test2, older_y_pred2)\n",
    "older_r2 = recall_score(older_y_test2, older_y_pred2)\n",
    "older_f2 = f1_score(older_y_test2, older_y_pred2)\n",
    "print('accuracy: %.2f' % older_a2 )\n",
    "print('precision: %.2f' % older_p2)\n",
    "print('recall: %.2f' % older_r2)\n",
    "print('F1: %.2f' % older_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개선된 confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confu = confusion_matrix(y_true = older_y_test2, y_pred = older_y_pred2)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(confu, annot=True, annot_kws={'size':15}, cmap='OrRd', fmt='.10g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "tr1 = pd.DataFrame([older_a1,older_p1,older_r1,older_f1])\n",
    "tr2 = pd.DataFrame([older_a2,older_p2,older_r2,older_f2])\n",
    "\n",
    "test_result = pd.concat([tr1.T, tr2.T], axis=0)\n",
    "test_result.columns=['Accuracy(정확도)', 'Precision(정밀도)', 'Recall(재현율)', 'F1']\n",
    "test_result.index = ['1차 Imbalance Data', '2차 Under-sampling']\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_lr2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c114509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print logistic regression's coef\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(range(len(older_lr.coef_[0])), older_lr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70086b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(((value, index) for index, value in enumerate(older_lr.coef_[0])), reverse = True)[:5])\n",
    "print(sorted(((value, index) for index, value in enumerate(older_lr.coef_[0])), reverse = True)[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934bef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_coef_pos_index = sorted(((value, index) for index, value in enumerate(older_lr2.coef_[0])), reverse = True)\n",
    "older_coef_neg_index = sorted(((value, index) for index, value in enumerate(older_lr2.coef_[0])), reverse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_index_vectorizer = older_id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_pos_top_word=[] \n",
    "older_pos_top_score=[]\n",
    "for coef in older_coef_pos_index[:10]:\n",
    "    print(invert_index_vectorizer[coef[1]], coef[0])\n",
    "    older_pos_top_word.append(invert_index_vectorizer[coef[1]])\n",
    "    older_pos_top_score.append(coef[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_neg_top_word=[] \n",
    "older_neg_top_score=[]\n",
    "for coef in older_coef_neg_index[:10]:\n",
    "    print(invert_index_vectorizer[coef[1]], coef[0])\n",
    "    older_neg_top_word.append(invert_index_vectorizer[coef[1]])\n",
    "    older_neg_top_score.append(coef[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd089d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_pos_top_word.reverse()\n",
    "older_pos_top_score.reverse()\n",
    "older_top_word=older_neg_top_word+ older_pos_top_word\n",
    "older_top_score = older_neg_top_score+ older_pos_top_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False # 한글 폰트 사용시 - 깨지는 문제 해결\n",
    "\n",
    "plt.bar(older_neg_top_word, older_neg_top_score, label = \"부정\", color = 'r')\n",
    "plt.bar(older_pos_top_word, older_pos_top_score, label = \"긍정\", color = 'g')\n",
    "\n",
    "plt.bar(range(len(older_top_score)), older_top_score)\n",
    "plt.xticks(range(len(older_top_word)), older_top_word)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9779d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.barh(older_neg_top_word, older_neg_top_score, label = \"부정\", color = 'r')\n",
    "plt.barh(older_pos_top_word, older_pos_top_score, label = \"긍정\", color = 'g')\n",
    "plt.legend()\n",
    "plt.xlabel('키워드별 Vectorized Score')\n",
    "plt.ylabel('Top 10 키워드')\n",
    "# Giving the tilte for the plot\n",
    "plt.title('2014~2018 개봉영화 후기 감정 분석')\n",
    "# Saving the plot as a 'png'\n",
    "plt.savefig('2BarPlot.png')\n",
    "# Displaying the bar plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_x_train = newer_train_df.drop(['PN'], axis=1)\n",
    "newer_y_train = newer_train_df['PN']\n",
    "newer_x_test = newer_test_df.drop(['PN'], axis=1)\n",
    "newer_y_test = newer_test_df['PN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit in training set\n",
    "newer_lr = LogisticRegression(random_state = 0)\n",
    "newer_lr.fit(newer_x_train,newer_y_train)\n",
    "\n",
    "# predict in test set\n",
    "newer_y_pred = newer_lr.predict(newer_x_test)\n",
    "\n",
    "newer_a1 = accuracy_score(newer_y_test, newer_y_pred)\n",
    "newer_p1 = precision_score(newer_y_test, newer_y_pred)\n",
    "newer_r1 =recall_score(newer_y_test, newer_y_pred)\n",
    "newer_f1= f1_score(newer_y_test, newer_y_pred)\n",
    "print('accuracy: %.2f' % newer_a1)\n",
    "print('precision: %.2f' % newer_p1)\n",
    "print('recall: %.2f' % newer_r1)\n",
    "print('F1: %.2f' % newer_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5bd40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "confu = confusion_matrix(y_true = newer_y_test, y_pred = newer_y_pred)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(confu, annot=True, annot_kws={'size':15}, cmap='OrRd', fmt='.10g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_positive_random_idx = newer_movie_df[newer_movie_df['PN']==1].sample(1000, random_state=12).index.tolist()\n",
    "newer_negative_random_idx = newer_movie_df[newer_movie_df['PN']==0].sample(1000, random_state=12).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87477ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_random_idx = newer_positive_random_idx + newer_negative_random_idx\n",
    "x = newer_tf_idf[newer_random_idx]\n",
    "y = newer_movie_df['PN'][newer_random_idx]\n",
    "newer_x_train2, newer_x_test2, newer_y_train2, newer_y_test2 = train_test_split(x, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_lr2 = LogisticRegression(random_state = 0)\n",
    "newer_lr2.fit(newer_x_train2, newer_y_train2)\n",
    "newer_y_pred2 = newer_lr2.predict(newer_x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in test set\n",
    "newer_a2 = accuracy_score(newer_y_test2, newer_y_pred2)\n",
    "newer_p2 = precision_score(newer_y_test2, newer_y_pred2)\n",
    "newer_r2 = recall_score(newer_y_test2,newer_y_pred2)\n",
    "newer_f2 = f1_score(newer_y_test2, newer_y_pred2)\n",
    "print('accuracy: %.2f' % newer_a2)\n",
    "print('precision: %.2f' % newer_p2)\n",
    "print('recall: %.2f' % newer_r2)\n",
    "print('F1: %.2f' % newer_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a482db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개선된 confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confu = confusion_matrix(y_true = newer_y_test2, y_pred = newer_y_pred2)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(confu, annot=True, annot_kws={'size':15}, cmap='OrRd', fmt='.10g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "tr1 = pd.DataFrame([newer_a1,newer_p1,newer_r1,newer_f1])\n",
    "tr2 = pd.DataFrame([newer_a2,newer_p2,newer_r2,newer_f2])\n",
    "\n",
    "test_result = pd.concat([tr1.T, tr2.T], axis=0)\n",
    "test_result.columns=['Accuracy(정확도)', 'Precision(정밀도)', 'Recall(재현율)', 'F1']\n",
    "test_result.index = ['1차 Imbalance Data', '2차 Under-sampling']\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303cf1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a60c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print logistic regression's coef\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(range(len(newer_lr.coef_[0])), newer_lr.coef_[0])\n",
    "\n",
    "print(sorted(((value, index) for index, value in enumerate(newer_lr.coef_[0])), reverse = True)[:5])\n",
    "print(sorted(((value, index) for index, value in enumerate(newer_lr.coef_[0])), reverse = True)[-5:])\n",
    "# enumerate: 인덱스 번호와 컬렉션의 원소를 tuple형태로 반환함\n",
    "\n",
    "newer_coef_pos_index = sorted(((value, index) for index, value in enumerate(newer_lr.coef_[0])), reverse = True)\n",
    "newer_coef_neg_index = sorted(((value, index) for index, value in enumerate(newer_lr.coef_[0])), reverse = False)\n",
    "newer_coef_pos_index[:10]\n",
    "newer_coef_neg_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33563e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일부 중요 원소들 단어사전 확인\n",
    "print('긍정리뷰 키워드: ', newer_id_to_word[79],newer_id_to_word[92]) \n",
    "print('부정리뷰 키워드: ', newer_id_to_word[416],newer_id_to_word[513]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b64991",
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_index_vectorizer = newer_id_to_word\n",
    "\n",
    "newer_pos_top_word=[] \n",
    "newer_pos_top_score=[]\n",
    "for coef in newer_coef_pos_index[:10]:\n",
    "    print(invert_index_vectorizer[coef[1]], coef[0])\n",
    "    newer_pos_top_word.append(invert_index_vectorizer[coef[1]])\n",
    "    newer_pos_top_score.append(coef[0])\n",
    "\n",
    "newer_neg_top_word=[] \n",
    "newer_neg_top_score=[]\n",
    "for coef in newer_coef_neg_index[:10]:\n",
    "    print(invert_index_vectorizer[coef[1]], coef[0])\n",
    "    newer_neg_top_word.append(invert_index_vectorizer[coef[1]])\n",
    "    newer_neg_top_score.append(coef[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad906ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_pos_top_word.reverse()\n",
    "newer_pos_top_score.reverse()\n",
    "newer_top_word=newer_neg_top_word+ newer_pos_top_word\n",
    "newer_top_score = newer_neg_top_score+ newer_pos_top_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52556cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False # 한글 폰트 사용시 - 깨지는 문제 해결\n",
    "\n",
    "plt.bar(newer_neg_top_word, newer_neg_top_score, label = \"부정\", color = 'r')\n",
    "plt.bar(newer_pos_top_word, newer_pos_top_score, label = \"긍정\", color = 'g')\n",
    "\n",
    "plt.bar(range(len(newer_top_score)), newer_top_score)\n",
    "plt.xticks(range(len(newer_top_word)), newer_top_word)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.barh(newer_neg_top_word, newer_neg_top_score, label = \"부정\", color = 'r')\n",
    "plt.barh(newer_pos_top_word, newer_pos_top_score, label = \"긍정\", color = 'g')\n",
    "plt.legend()\n",
    "plt.xlabel('키워드별 Vectorized Score')\n",
    "plt.ylabel('Top 10 키워드')\n",
    "# Giving the tilte for the plot\n",
    "plt.title('2019~2023 개봉영화 후기 감정 분석')\n",
    "# Saving the plot as a 'png'\n",
    "plt.savefig('2BarPlot.png')\n",
    "# Displaying the bar plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35685644",
   "metadata": {},
   "source": [
    "# 모델별 크로스 검증\n",
    "1. 구영화 훈련 > 신영화 검증\n",
    "2. 신영화 훈련 > 구영화 검증\n",
    "필요 작업: 각 test_set의 feature 개수 통일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross체크용 회귀모델 재훈련\n",
    "cross_older_lr = LogisticRegression(random_state = 0)\n",
    "cross_older_lr.fit(older_x_train2, older_y_train2)\n",
    "cross_older_y_pred = cross_older_lr.predict(newer_x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_older_a1 = accuracy_score(newer_y_test2, cross_older_y_pred)\n",
    "cross_older_p1 = precision_score(newer_y_test2, cross_older_y_pred)\n",
    "cross_older_r1 = recall_score(newer_y_test2,cross_older_y_pred)\n",
    "cross_older_f1 = f1_score(newer_y_test2, cross_older_y_pred)\n",
    "print('accuracy: %.2f' % cross_older_a1)\n",
    "print('precision: %.2f' % cross_older_p1)\n",
    "print('recall: %.2f' % cross_older_r1)\n",
    "print('F1: %.2f' % cross_older_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d78882",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_newer_lr = LogisticRegression(random_state = 0)\n",
    "cross_newer_lr.fit(newer_x_train, newer_y_train)\n",
    "cross_newer_y_pred = cross_newer_lr.predict(older_x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
